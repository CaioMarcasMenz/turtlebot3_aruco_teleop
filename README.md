# TurtleBot3 Marker-Teleoperation  
### RealSense D435 + ArUco-Lenkrad (ROS2 Humble)

Dieses Projekt ermÃ¶glicht die intuitive Steuerung eines **TurtleBot3 Burger** mithilfe eines **ArUco-Markers**, der wie ein physisches Lenkrad verwendet wird.  
Die RealSense-Kamera erkennt **Ausrichtung und Entfernung** des Markers und wandelt diese automatisch in Fahrbefehle (`cmd_vel`) um.

Entwickelt fÃ¼r **Kinder-Workshops, Schulen und Robotik-AGs**, um spielerisch Robotik, Computer Vision und ROS2 zu vermitteln.

---

## ğŸ–¼ï¸ Ãœbersichtsgrafik

> *(Bitte den Pfad spÃ¤ter durch den GitHub-Link zu deiner eigenen Datei ersetzen.)*

![Teleoperation Illustration](/mnt/data/A_2D_digital_illustration_displays_a_top-down_view.png)

---

## ğŸ¯ Ziel des Projekts

- Steuerung des TurtleBot3 ohne Joystick oder Tastatur  
- Spielerischer Einstieg in Robotik & Computer Vision  
- Demonstration wichtiger Robotik-Konzepte:
  - Marker-Erkennung  
  - Pose-SchÃ¤tzung  
  - Abstands- und Winkelregelung  
  - ROS2-Kommunikation  
- Fehlertolerante Steuerung:
  â†’ Wenn der Marker kurz verschwindet, fÃ¤hrt der Roboter **mit halber letzter Geschwindigkeit** weiter.

---

## ğŸ§° Hardware

- **TurtleBot3 Burger**
- **Intel RealSense D435**
- PC/Laptop mit:
  - **Ubuntu 22.04**
  - **ROS2 Humble**
  - USB 3.0
- ArUco-Marker (ID **2**, Dictionary: `DICT_ARUCO_ORIGINAL`)  
  â†’ Empfehlung: auf **Karton** montieren

---

## ğŸ§‘â€ğŸ’» Software-Voraussetzungen

- ROS2 Humble  
- RealSense SDK (**librealsense2**)  
- Python 3  
- Python-Pakete (`requirements.txt`):
  - `opencv-contrib-python`
  - `numpy`
  - `pyrealsense2`
  - `rclpy`

---

## ğŸ“¦ Installation

### 1. ROS2-Workspace anlegen

```bash
mkdir -p ~/ros2_ws/src
cd ~/ros2_ws
```

---

### 2. Repository klonen

```bash
cd ~/ros2_ws/src
git clone https://github.com/CaioMarcasMenz/turtlebot3_aruco_teleop.git turtlebot3_aruco_teleop
```

---

### 3. Python-Umgebung (optional, aber empfohlen)

Zur sauberen Trennung aller Python-AbhÃ¤ngigkeiten:

```bash
cd ~/ros2_ws
python3 -m venv .venv
source .venv/bin/activate
```

---

### 4. Python-AbhÃ¤ngigkeiten installieren

```bash
pip install -r src/turtlebot3_aruco_teleop/requirements.txt
```

---

### 5. Workspace bauen

```bash
cd ~/ros2_ws
colcon build
source install/setup.bash
export TURTLEBOT3_MODEL=burger
```

---

## ğŸ“· Intel RealSense D435 einrichten

### 1. RealSense SDK installieren (falls noch nicht geschehen)

- `librealsense2` installieren  
- Firmware/udev-Regeln Ã¼bernehmen  
- Einmal neu starten

### 2. Kamera testen

```bash
realsense-viewer
```

Wenn ein Kamerabild angezeigt wird â†’ RealSense funktioniert.

---

## â–¶ï¸ Demo starten

### 1. TurtleBot3 vorbereiten

```bash
export TURTLEBOT3_MODEL=burger
ros2 launch turtlebot3_bringup robot.launch.py
```

---

### 2. Marker-Teleoperation starten

Auf deinem Rechner (mit angeschlossener Kamera):

```bash
cd ~/ros2_ws
source .venv/bin/activate   # falls genutzt
source install/setup.bash
ros2 run turtlebot3_aruco_teleop marker_teleop
```

Ein Vollbild-Fenster Ã¶ffnet sich.  
Das Live-Bild der RealSense erscheint, und der Roboter reagiert auf den Marker.

---

## ğŸ¤– Funktionsweise

### 1. Marker-Erkennung

OpenCV erkennt den Marker mit:

- neuer API â†’ `cv2.aruco.ArucoDetector`  
- alter API â†’ `cv2.aruco.detectMarkers`  

â†’ Der Code unterstÃ¼tzt **beide Varianten automatisch**.

---

### 2. Pose-SchÃ¤tzung

Wenn mÃ¶glich:

```python
cv2.aruco.estimatePoseSingleMarkers()
```

Sonst Fallback:

```python
cv2.solvePnP()
```

---

## ğŸ›ï¸ Steuerlogik

### ğŸ“Œ Distanz â†’ VorwÃ¤rts / RÃ¼ckwÃ¤rts

Alle Distanzwerte sind **in cm** definiert.

| Variable | Bedeutung |
|---------|-----------|
| `DIST_NEUTRAL_CAMERA_CM` | neutrale Entfernung (Stopp) |
| `DIST_MAX_FORWARD_OFFSET_CM` | maximale AnnÃ¤herung |
| `DIST_MAX_BACKWARD_OFFSET_CM` | maximale Entfernung |
| `DIST_DEADZONE_OFFSET_CM` | Bereich ohne Bewegung |

**Abgeleitete Bereiche:**

- **VorwÃ¤rtsbereich**: Marker **nÃ¤her** als die Totzone  
- **Totzone**: Marker im **Neutralbereich** â†’ Roboter stoppt  
- **RÃ¼ckwÃ¤rtsbereich**: Marker **weiter weg** als die Totzone  

**Besonderheiten:**

- Geschwindigkeit wird **linear skaliert**  
- Distanz wird **Ã¼ber 3 Messungen geglÃ¤ttet**

---

### ğŸ“Œ Drehung â†’ Links / Rechts

FÃ¼r die Rotation wird `rvec[1]` (Y-Achse) genutzt.

Parameter:

- `ANGULAR_START` â€“ minimale Reaktionsschwelle  
- `ANGULAR_END` â€“ maximale SÃ¤ttigung  
- GlÃ¤ttung Ã¼ber die letzten 3 Werte

**Bereiche:**

- zwischen `-ANGULAR_START â€¦ +ANGULAR_START` â‡’ **geradeaus**  
- auÃŸerhalb â‡’ **proportionale Drehung** bis `BURGER_MAX_ANG_VEL`

---

### ğŸ“Œ Marker auÃŸer Sicht â†’ Fehlerrobust

Wenn der Marker nicht erkannt wird:

```python
speed_factor = 1 / (2 - marker_seen_flag)
```

- Marker sichtbar â†’ **1.0**
- Marker weg â†’ **0.5**

â†’ Der Roboter fÃ¤hrt **ruhig und kontrolliert weiter**, statt abrupt zu stoppen.  
Perfekt fÃ¼r Workshops mit Kindern.

---

## ğŸ–¥ï¸ Visualisierung

- Vollbildmodus (`WINDOW_FULLSCREEN`)
- Bild auf **1920Ã—1080** skaliert
- Overlay zeigt:
  - Linear- & Rotationsgeschwindigkeit  
  - Richtungstext (Links/Rechts/VorwÃ¤rts/RÃ¼ckwÃ¤rts/Stop)  
  - GeschÃ¤tzte Distanz  
  - â€Marker nicht sichtbarâ€œ-Hinweis  

---

## ğŸ‘¶ Tipps fÃ¼r Workshops

- Marker auf **A4-Karton** kleben (fÃ¼hlt sich wie ein echtes Lenkrad an)  
- Kamera ca. **1 m** Abstand  
- Parcours mit Kreppband auf dem Boden markieren  
- Kindern zuerst das **Live-Kamerabild** zeigen  
- Einfaches Merkschema:
  - â€**Drehen = Lenken**â€œ
  - â€**NÃ¤her ran = Gas geben**â€œ
  - â€**Weiter weg = RÃ¼ckwÃ¤rts**â€œ

---

## ğŸ”§ Kalibrierung

### Bias-Faktor

Der RealSense Z-Wert (`tvec[2]`) ist stark setupspezifisch.  
Daher wird er durch einen empirischen Faktor geteilt:

```python
bias = 13.8
tvec_z = tvec[2] / bias
```

Typischer Wertebereich: **13.5â€“14.3**  
â†’ hÃ¤ngt ab von Kameraabstand, MarkergrÃ¶ÃŸe und Beleuchtung.

---
